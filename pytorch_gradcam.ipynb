{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa285374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os, json\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a41c3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize and take the center part of image to what our model expects\n",
    "def get_input_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])       \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    # unsqeeze converts single image to batch of 1\n",
    "    return transf(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7541f09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_fn = \"models/orig_20220627-235055-seresnext50_32x4d-224/last.pth.tar\"\n",
    "im_path = \"data/orig_o\"\n",
    "\n",
    "fl_dict = {}\n",
    "for idx, fl in enumerate(glob(f\"{im_path}/*\")):\n",
    "    bn = os.path.basename(fl)\n",
    "    fl_dict[bn] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce1362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f845724e72c45bcb27e928881ed6f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = timm.create_model(\n",
    "        'seresnext50_32x4d',\n",
    "        num_classes=300,\n",
    "        in_chans=3,\n",
    "        pretrained=True,\n",
    "        checkpoint_path=ckpt_fn)\n",
    "\n",
    "target_layers = model.layer4\n",
    "\n",
    "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
    "abl = AblationCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
    "eig = EigenCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
    "\n",
    "images = glob(f\"{im_path}/**/*.*\", recursive=True)\n",
    "for im_fn in tqdm(images, total=len(list(images))):\n",
    "    bn = os.path.basename(im_fn)\n",
    "    cat = fl_dict[im_fn.split(\"\\\\\")[-2]]\n",
    "    \n",
    "    img = Image.open(im_fn)\n",
    "    img_t = get_input_tensors(img)\n",
    "    test_img = np.array(img.resize((224, 224)), dtype='float32')\n",
    "    test_img /= 255\n",
    "\n",
    "    targets = [ClassifierOutputTarget(cat)]\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=img_t, targets=targets)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "    visualization = show_cam_on_image(test_img, grayscale_cam, use_rgb=True)\n",
    "    plt.imshow(visualization)\n",
    "    plt.savefig(f\"outs/o_o/gradcam/{bn}\")\n",
    "    plt.clf()\n",
    "    \n",
    "#     grayscale_abl = abl(input_tensor=img_t, targets=targets)\n",
    "#     grayscale_abl = grayscale_abl[0, :]\n",
    "\n",
    "#     visualization = show_cam_on_image(test_img, grayscale_abl, use_rgb=True)\n",
    "#     plt.imshow(visualization)\n",
    "#     plt.savefig(f\"outs/o_o/ablationcam/{bn}\")\n",
    "#     plt.clf()\n",
    "    \n",
    "    grayscale_eig = eig(input_tensor=img_t, targets=targets)\n",
    "    grayscale_eig = grayscale_eig[0, :]\n",
    "\n",
    "    visualization = show_cam_on_image(test_img, grayscale_eig, use_rgb=True)\n",
    "    plt.imshow(visualization)\n",
    "    plt.savefig(f\"outs/o_o/eigencam/{bn}\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da50bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
