{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c8598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os, json\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b726ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])       \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((600, 600)),\n",
    "        transforms.CenterCrop(600),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    return transf(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faec1aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4577\n"
     ]
    }
   ],
   "source": [
    "ckpt_fn = \"models/resolution/20220722-163041-sequencer2d_l-600/last.pth.tar\"\n",
    "im_path = \"data/orig_o\"\n",
    "out_path = \"resolution/600_s2d\"\n",
    "model_type = \"sequencer2d_l\"\n",
    "\n",
    "fl_dict = {}\n",
    "for idx, fl in enumerate(glob(f\"{im_path}/*\")):\n",
    "    bn = os.path.basename(fl)\n",
    "    fl_dict[bn] = idx\n",
    "    \n",
    "images = []\n",
    "for im_fn in glob(f\"{im_path}/**/*.*\", recursive=True):\n",
    "    bn = os.path.basename(im_fn)\n",
    "    images.append(im_fn)\n",
    "    \n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6fdc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "        model_type,\n",
    "        num_classes=300,\n",
    "        in_chans=3,\n",
    "        checkpoint_path=ckpt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ce346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5f77630d3e4716b26a09d7f92dda67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for im_fn in tqdm(images, total=len(list(images))):\n",
    "    curr_dir = dir()\n",
    "    cam_list = [[\"fullgrad\", FullGrad(model=model, target_layers=[])]]\n",
    "    \n",
    "    bn = os.path.basename(im_fn)\n",
    "    cat = fl_dict[im_fn.split(\"/\")[-2]]\n",
    "    \n",
    "    img = Image.open(im_fn)\n",
    "    img_t = get_input_tensors(img)\n",
    "    test_img = np.array(img.resize((600, 600)), dtype='float32')\n",
    "    test_img /= 255\n",
    "\n",
    "    targets = [ClassifierOutputTarget(cat)]\n",
    "    \n",
    "    for cam_str, cam_method in cam_list:\n",
    "        grayscale_cam = cam_method(input_tensor=img_t, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        visualization = show_cam_on_image(test_img, grayscale_cam, use_rgb=True)\n",
    "        plt.imshow(visualization)\n",
    "        if not os.path.exists(f\"outs/{out_path}/{cam_str}/{bn}\"):\n",
    "            try:\n",
    "\n",
    "                plt.savefig(f\"outs/{out_path}/{cam_str}/{bn}\")\n",
    "            except FileNotFoundError:\n",
    "                os.makedirs(f\"outs/{out_path}/{cam_str}/\")\n",
    "            plt.close()\n",
    "        \n",
    "        del grayscale_cam\n",
    "        \n",
    "    for name in dir():\n",
    "        if name not in curr_dir and name != \"curr_dir\":\n",
    "            del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4993c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
