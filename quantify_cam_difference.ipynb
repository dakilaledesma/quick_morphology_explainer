{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c8598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os, json\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b726ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_transform():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])       \n",
    "    transf = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "\n",
    "    return transf\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    transf = get_input_transform()\n",
    "    return transf(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4508436",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_fn = \"models/20220703-182810-resnet50-224/last.pth.tar\"\n",
    "im_path = \"data/orig_o\"\n",
    "out_path = \"o_o\"\n",
    "\n",
    "fl_dict = {}\n",
    "for idx, fl in enumerate(glob(f\"{im_path}/*\")):\n",
    "    bn = os.path.basename(fl)\n",
    "    fl_dict[bn] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6fdc62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "        'resnet50',\n",
    "        num_classes=300,\n",
    "        in_chans=3,\n",
    "        pretrained=True,\n",
    "        checkpoint_path=ckpt_fn)\n",
    "\n",
    "target_layers = model.layer4\n",
    "\n",
    "images = glob(f\"{im_path}/**/*.*\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: You are using ScoreCAM with target layers, however ScoreCAM will ignore them.\n",
      "Warning: target_layers is ignored in FullGrad. All bias layers will be used instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c52c1458728477e8c8c9f6b5a9c4b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 9/128 [01:39<22:50, 11.51s/it]"
     ]
    }
   ],
   "source": [
    "'''GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad'''\n",
    "\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "eig = EigenCAM(model=model, target_layers=target_layers)\n",
    "\n",
    "cam_list = [\n",
    "    [\"gradcam\", GradCAM(model=model, target_layers=target_layers)],\n",
    "    [\"scorecam\", ScoreCAM(model=model, target_layers=target_layers)],\n",
    "    [\"gradcampp\", GradCAMPlusPlus(model=model, target_layers=target_layers)],\n",
    "    [\"xgradcam\", XGradCAM(model=model, target_layers=target_layers)],\n",
    "    [\"eigencam\", EigenCAM(model=model, target_layers=target_layers)],\n",
    "    [\"fullgrad\", FullGrad(model=model, target_layers=target_layers)],\n",
    "]\n",
    "\n",
    "def process(im_fn, fl_dict, cam_list):\n",
    "    bn = os.path.basename(im_fn)\n",
    "    cat = fl_dict[im_fn.split(\"/\")[-2]]\n",
    "    \n",
    "    img = Image.open(im_fn)\n",
    "    img_t = get_input_tensors(img)\n",
    "    test_img = np.array(img.resize((224, 224)), dtype='float32')\n",
    "    test_img /= 255\n",
    "\n",
    "    targets = [ClassifierOutputTarget(cat)]\n",
    "    \n",
    "    for cam_str, cam_method in cam_list:\n",
    "        grayscale_cam = cam_method(input_tensor=img_t, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        visualization = show_cam_on_image(test_img, grayscale_cam, use_rgb=True)\n",
    "        plt.imshow(visualization)\n",
    "        try:\n",
    "            plt.savefig(f\"outs/{out_path}/{cam_str}/{bn}\")\n",
    "        except FileNotFoundError:\n",
    "            os.makedirs(f\"outs/{out_path}/{cam_str}/\")\n",
    "        plt.clf()\n",
    "\n",
    "Parallel(n_jobs=8)(delayed(process)(im_fn, fl_dict, cam_list) for im_fn in tqdm(images, total=len(list(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce346e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
